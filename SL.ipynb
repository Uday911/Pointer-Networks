{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from functools import reduce\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Manager\n",
    "import time\n",
    "import math\n",
    "from scipy import signal\n",
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn import functional as F\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "from itertools import permutations\n",
    "from torch.multiprocessing import Pool\n",
    "from itertools import combinations,permutations,product\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "data_path = '/home/cdsw/Data/'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import torch\n",
    "cuda=None\n",
    "\n",
    "class EMS():\n",
    "    '''\n",
    "    Class to keep track of empty maximal spaces in box.\n",
    "    self.spaces is a N x 2 x 3 tensor, where N is the current number of empty maximal spaces.\n",
    "    Each space is reprsented by two coordinate triplets; the first triplet is the coordinates of the corner closest to\n",
    "    (0,0,0) and the second is the opposite corner.\n",
    "    '''\n",
    "    def __init__(self, dims,full_support = False):\n",
    "        '''\n",
    "        Input: \n",
    "            dims: size of box as list of three numbers\n",
    "        '''\n",
    "\n",
    "        self.spaces = torch.tensor([[0,0,0],dims], device=cuda).unsqueeze(0).double()\n",
    "        self.items = torch.tensor([[0,0,0],[0,0,0]], device=cuda).unsqueeze(0).double()\n",
    "        self.box = torch.tensor(dims).double()\n",
    "        self.full_support = full_support\n",
    "    def cleave(self, item, sort=True):\n",
    "        '''\n",
    "        given an item to insert, identify all Maximal Empty Spaces that intersect it and cleave those spaces into\n",
    "        new maximal empty spaces.\n",
    "        \n",
    "        Input: \n",
    "            item: 2 x 3 tensor w/ coordinates of the two corners of the item to be inserted\n",
    "            sort: whether or not to sort resulting list of maximal spaces.\n",
    "        '''\n",
    "        if len(item.shape) == 2:\n",
    "            item = item.unsqueeze(0)\n",
    "        self.items = torch.cat([self.items, item],dim=0)\n",
    "#         print('item',item)\n",
    "#         print('self.items',self.items)\n",
    "#         print('self.spaces',self.spaces)\n",
    "        #high coords of item higher than low coords of spaces?\n",
    "        diff_1 = item[:,1,:] > self.spaces[:,0,:]\n",
    "#         print('diff_1',diff_1)\n",
    "        #low coords of item lower than higher coords of spaces?\n",
    "        diff_2 = item[:,0,:] < self.spaces[:,1,:]\n",
    "#         print('diff_2',diff_2)\n",
    "        #intersection occurs if both conditions are met on all 3 axes\n",
    "        intersect_inds = (diff_1 * diff_2).all(dim=-1)\n",
    "#         print('intersect_inds',intersect_inds)\n",
    "        \n",
    "        intersect_spaces = self.spaces[intersect_inds]\n",
    "#         print('intersect_spaces',intersect_spaces)\n",
    "        new_spaces = []\n",
    "        for dim in range(3):\n",
    "            low = intersect_spaces.clone()\n",
    "            high = intersect_spaces.clone()\n",
    "            \n",
    "            low[:,1,dim] = item[:,0,dim]\n",
    "            high[:,0,dim] = item[:,1,dim]\n",
    "            \n",
    "            new_spaces = new_spaces + [low, high]\n",
    "        new_spaces = torch.cat(new_spaces, dim=0)\n",
    "#         print('new_spaces',new_spaces)\n",
    "        new_spaces = self.elim_zero(new_spaces)\n",
    "#         print('new_spaces',new_spaces)\n",
    "        old_spaces = self.spaces[~intersect_inds]\n",
    "#         print('old_spaces',old_spaces)\n",
    "        new_spaces = self.elim_insc(new_spaces, old_spaces)\n",
    "#         print('new_spaces',new_spaces)\n",
    "        all_spaces = torch.cat([new_spaces, old_spaces], dim=0)\n",
    "#         print('all_spaces',all_spaces)\n",
    "        if sort:\n",
    "            all_spaces = all_spaces.flip(dims=(-1,)).unique(dim=0).flip(dims=(-1,))\n",
    "#             all_spaces = all_spaces.unique(dim=0)\n",
    "        self.spaces = all_spaces\n",
    "        \n",
    "        return self.spaces    \n",
    "    \n",
    "    def elim_zero(self, new_spaces):\n",
    "        '''eliinate spaces with volume 0'''\n",
    "        lengths = new_spaces[:,1,:]  - new_spaces[:,0,:]\n",
    "        nonzero = (lengths > 0).all(dim=-1)\n",
    "        return new_spaces[nonzero]\n",
    "    \n",
    "    def elim_insc(self, new_spaces, old_spaces):\n",
    "        '''eliminate new spaces that are completely inscribed within another space (new or existing)'''\n",
    "        all_spaces_m = torch.cat([new_spaces, old_spaces], dim=0).unsqueeze(0)\n",
    "        new_spaces_m = new_spaces.unsqueeze(1)\n",
    "        \n",
    "        all_spaces_m = all_spaces_m.expand(new_spaces_m.shape[0],-1,-1,-1)\n",
    "        new_spaces_m = new_spaces_m.expand(-1, all_spaces_m.shape[1],-1,-1)\n",
    "        \n",
    "        low = (new_spaces_m[...,0,:] >= all_spaces_m[...,0,:]).all(dim=-1)\n",
    "        high = (new_spaces_m[...,1,:] <= all_spaces_m[...,1,:]).all(dim=-1)\n",
    "        both = low * high\n",
    "        diag = torch.arange(new_spaces_m.shape[0], device=cuda)\n",
    "        both[diag,diag] = False\n",
    "        keep = ~(both.any(dim=-1))\n",
    "        return new_spaces[keep]\n",
    "        \n",
    "    def find_space(self, item,packed_items,packed_items_pos):\n",
    "        '''\n",
    "        Input:\n",
    "            Item: length 3 tensor (l, w, h)\n",
    "        Finds first empty space where item will fit\n",
    "        '''\n",
    "        item = item[...,:3]\n",
    "#         print(self.spaces)\n",
    "        space_sizes = (self.spaces[:,1,:] - self.spaces[:,0,:])\n",
    "        \n",
    "        valid = (space_sizes >= item).all(dim=-1).nonzero()\n",
    "        if len(valid) == 0:\n",
    "            return None\n",
    "        if (self.spaces[valid[0].item()][0][2] == 0) | (self.full_support == False):\n",
    "            out = self.spaces[valid[0].item()]\n",
    "        elif (self.spaces[valid[0].item()][0][2] > 0) & (self.full_support == True):\n",
    "            dim1 = packed_items[:,:3].unsqueeze(1)\n",
    "            pos1 = packed_items_pos[:,0].unsqueeze(1)\n",
    "            itemsize = item.unsqueeze(0).unsqueeze(0).clone().double()\n",
    "            spaces = self.spaces[valid[:,0]].clone()\n",
    "            pos2 = spaces[:,0].unsqueeze(1)\n",
    "            dim2 = itemsize.expand(pos2.shape[0],1,3)\n",
    "            v = self.intersection_volume3(dim1, pos1, dim2, pos2).squeeze(0)\n",
    "            p1mat = pos1.expand(-1,pos2.shape[0],-1)\n",
    "            p2mat = pos2.expand(-1,pos1.shape[0],-1).permute(1,0,2)\n",
    "\n",
    "            z_below = p1mat[...,2] < p2mat[...,2]\n",
    "            z_condition = v[...,2] == 0\n",
    "            x_condition = v[...,0] > 0\n",
    "            y_condition = v[...,1] > 0\n",
    "\n",
    "            condition_mask = x_condition * y_condition * z_condition * z_below\n",
    "\n",
    "            masked = v[...,:2] * condition_mask.unsqueeze(-1)\n",
    "            ground_support_areas = masked.prod(dim=-1).sum(dim=0)\n",
    "\n",
    "            ground_support_ratios = ground_support_areas / itemsize[...,:2].prod(dim=-1).squeeze()\n",
    "            satisfied = ground_support_ratios==1\n",
    "            spaces = spaces[satisfied]\n",
    "            if spaces.shape[0] > 0:\n",
    "                out = spaces[0]\n",
    "            else:\n",
    "                out = None\n",
    "        else:\n",
    "            out = None\n",
    "        return out\n",
    "    \n",
    "    def intersection_volume3(self,dim1, pos1, dim2, pos2):\n",
    "        '''\n",
    "        Takes two pairs of tensors of shape N1 x B x 3 and N2 x B x 3\n",
    "        dim1 and pos1 give the dimensions and positions of the first set of items\n",
    "        dim2 and pos2 give the dimensions and positions of the second set of items\n",
    "        returns B x N1 x N2 tensor containing volume of intersections \n",
    "        between each item in the first set and each item in the second set\n",
    "        '''\n",
    "        if dim1.shape[-1] != 3 or dim2.shape[-1] != 3:\n",
    "            #print('last dim not 3')\n",
    "            dim1 = dim1[...,:3]\n",
    "            dim2 = dim2[...,:3]\n",
    "\n",
    "        min1 = pos1\n",
    "        min2 = pos2\n",
    "\n",
    "        max1 = min1 + dim1\n",
    "        max2 = min2 + dim2\n",
    "\n",
    "        len1 = dim1.shape[0]\n",
    "        len2 = dim2.shape[0]\n",
    "\n",
    "        inter_dims = []\n",
    "\n",
    "        #reshape N1 x B x 3 and N2 x B x 3 to N1 x N2 x B x 3 each.\n",
    "\n",
    "        dim_i = dim1.unsqueeze(0).expand(len2,-1, -1, -1).transpose(0,1)\n",
    "        dim_j = dim2.unsqueeze(0).expand(len1,-1, -1, -1)\n",
    "\n",
    "        max_i = max1.unsqueeze(0).expand(len2,-1, -1, -1).transpose(0,1)\n",
    "        max_j = max2.unsqueeze(0).expand(len1,-1, -1, -1)\n",
    "\n",
    "        min_i = min1.unsqueeze(0).expand(len2,-1, -1, -1).transpose(0,1)\n",
    "        min_j = min2.unsqueeze(0).expand(len1,-1, -1, -1)\n",
    "\n",
    "\n",
    "        #max of obj i - min of obj j\n",
    "        d1 = max_i - min_j\n",
    "        #max of obj j - min of obj i\n",
    "        d2 = max_j - min_i\n",
    "\n",
    "        #intersection exists if d1 >= 0 and d2 >=0\n",
    "        #size of intersection given by min(dim_, dim_j, d1, d2)\n",
    "\n",
    "        inter_dim = torch.min(torch.min(torch.min(dim_i, dim_j), d1), d2)\n",
    "\n",
    "        #if any of these is negative, no intersection, so clamp negatives to 0\n",
    "        #inter_dim = torch.clamp(inter_dim, min=0)\n",
    "\n",
    "        #return torch.prod(inter_dim, dim=-1).permute(-1,0,1)\n",
    "        return inter_dim.permute(2,0,1,-1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def pack(box, items):\n",
    "    '''\n",
    "    Inputs:\n",
    "        boxes: length 4 tensor (l, w, h, weight capacity)\n",
    "        items: Nx4 tensor -- N items x (l, w, h, weight capacity)\n",
    "    Returns:\n",
    "        ems object with packed items\n",
    "        indices of items that were packed (some items may not have fit.)\n",
    "    \n",
    "    Packs all items into box. Items are assumed to have already been ordered and rotated \n",
    "    (and their dimensions should reflect that)\n",
    "    '''\n",
    "    items = items.float()\n",
    "    box = box.float()\n",
    "    ems = EMS([i for i in box[...,:3]],full_support=False)\n",
    "    packed_indices = []\n",
    "    total_weight = 0\n",
    "    packed_items = torch.tensor([[0,0,0,0]], device=cuda,dtype=torch.double)\n",
    "    packed_items_pos = torch.tensor([[0,0,0],[0,0,0]], device=cuda,dtype=torch.double).unsqueeze(0)\n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        if total_weight + item[...,3] > box[...,3]:\n",
    "            continue\n",
    "        else:\n",
    "            total_weight = total_weight + item[...,3]\n",
    "\n",
    "        space = ems.find_space(item,packed_items,packed_items_pos)\n",
    "        \n",
    "        if space is None:\n",
    "            continue\n",
    "            \n",
    "        new_origin = space[0]\n",
    "        new_item = torch.stack([new_origin, new_origin + item[...,:3]])\n",
    "            \n",
    "        ems.cleave(new_item)\n",
    "        packed_indices.append(i)\n",
    "        packed_items = torch.cat([packed_items,item.clone().double().unsqueeze(0)],dim=0)\n",
    "        packed_items_pos = torch.cat([packed_items_pos,new_item.clone().unsqueeze(0)])\n",
    "        if ems.spaces.shape[0] == 0:\n",
    "#             print('&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&')\n",
    "#             print('ems.spaces',ems.spaces)\n",
    "            break\n",
    "    return ems, packed_indices, packed_items, packed_items_pos\n",
    "\n",
    "\n",
    "\n",
    "def break_list(sublst_ln,lst):\n",
    "    \"\"\"\n",
    "    Divides given list into sublists of given length\n",
    "    \"\"\"\n",
    "    all_parts = len(lst)//sublst_ln\n",
    "    last_part = len(lst)%sublst_ln\n",
    "    tmp = []\n",
    "    for i in range(all_parts):\n",
    "        tmp.append(lst[i*sublst_ln:(i+1)*sublst_ln])\n",
    "    if last_part > 0:\n",
    "        tmp.append(lst[sublst_ln*all_parts:])\n",
    "    return tmp\n",
    "def surface_area(dms):\n",
    "    l,w,h = dms\n",
    "    return 2*l*w+2*l*h+2*w*h\n",
    "\n",
    "def uniques(a):\n",
    "    x, ix = np.unique(a, return_index=True)\n",
    "    return np.array(a)[sorted(ix)].tolist()\n",
    "\n",
    "\n",
    "def simulate(inp):\n",
    "#     inp = pickle.loads(inp)\n",
    "    batch_id,items,boxes,items_seq,items_ori = inp\n",
    "    total_items_vol = items[:,:3].prod(1).sum().item()\n",
    "    items_seq = uniques(items_seq)\n",
    "    items_ori = items_ori[items_seq,:]\n",
    "    items = items[torch.LongTensor(items_seq).expand(4,-1).T,items_ori]\n",
    "    box = boxes[0]\n",
    "    if len(items_seq) == 0:\n",
    "        print('new_items_seq',items_seq)\n",
    "        print('size',items.size())\n",
    "        print('batch_id',batch_id)\n",
    "    ems, indices,packed_items, packed_items_pos = pack(box, items)\n",
    "    mx = packed_items_pos[:,1].max(axis=0)\n",
    "    x,y,z = tuple(mx.values.tolist())\n",
    "    \n",
    "    packed_items_vol = packed_items[:,:3].prod(dim=1).sum().item()\n",
    "    portion = packed_items_vol/total_items_vol\n",
    "    \n",
    "    packed_items_surf = (2*packed_items[:,(0,1)].prod(dim=1) + 2*packed_items[:,(1,2)].prod(dim=1) + 2*packed_items[:,(0,2)].prod(dim=1)).sum().item()\n",
    "    tot_items_surf = (2*items[:,(0,1)].prod(dim=1) + 2*items[:,(1,2)].prod(dim=1) + 2*items[:,(0,2)].prod(dim=1)).sum().item()\n",
    "    portion_surf = packed_items_surf/tot_items_surf\n",
    "    \n",
    "    \n",
    "    new_dim = (x,y,z,packed_items[:,3].sum().item())\n",
    "    if z > 0:\n",
    "        occupied = packed_items_vol/(x*y*z)\n",
    "    else:\n",
    "        occupied = 0\n",
    "    \n",
    "#     all_hus_T = torch.tensor([i[0]+[i[1]] for i in all_hus])\n",
    "    \n",
    "#     nearest_hu = all_hus_T[0]\n",
    "\n",
    "    \n",
    "    cubes_n = len(indices)\n",
    "    cubes_packed = torch.LongTensor(items_seq)[indices].tolist()\n",
    "    if len(cubes_packed) > 0:\n",
    "        nearest_hu = boxes[(boxes >= torch.tensor(new_dim)).all(axis=1)][0]\n",
    "        reality_score = sum(1/nearest_hu[:3]).sum().item()\n",
    "        fill_for_nearest_hu = packed_items_vol/nearest_hu[:3].prod().item()\n",
    "        nearest_hu = nearest_hu[:3].tolist()\n",
    "        fill_rate = packed_items_vol/box[:3].prod().item()\n",
    "        fill_rate_for_best_box = packed_items_vol/(x*y*z)\n",
    "        \n",
    "    else:\n",
    "        nearest_hu = []\n",
    "        reality_score = 0\n",
    "        fill_for_nearest_hu = 0\n",
    "        fill_rate = 0\n",
    "        fill_rate_for_best_box = 0\n",
    "    items_seq_next = [i for i in items_seq if i not in cubes_packed]\n",
    "    weights_filled = packed_items[:,3].sum().item()\n",
    "#     return packed_items_pos,items,cubes_n,occupied,cubes_packed,weights_filled,new_dim,portion,reality_score,fill_for_nearest_hu,portion_surf,inp[0],(nearest_hu.tolist()[:3],nearest_hu.tolist()[3])\n",
    "    return batch_id,cubes_n,len(items_seq),cubes_packed,indices,items_seq_next,portion,fill_for_nearest_hu,nearest_hu,items.tolist(),box.tolist(),fill_rate,fill_rate_for_best_box,portion\n",
    "\n",
    "def get_action(logits,max_prob=False):\n",
    "    if max_prob == True:\n",
    "        prob, indices = torch.max(logits, 2)\n",
    "        return indices\n",
    "    else:\n",
    "        m = Categorical(logits=logits)\n",
    "        return m.sample()\n",
    "    \n",
    "def to_cuda(x):\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self,MODEL_INPUT_SIZE,hidden_size, weight_size,ITEMS_SEQ_LN):\n",
    "        super().__init__()\n",
    "        self.input_size = MODEL_INPUT_SIZE\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_size = weight_size\n",
    "        self.ITEMS_SEQ_LN = ITEMS_SEQ_LN\n",
    "        \n",
    "        RNN = nn.GRU\n",
    "        RNNCell = nn.GRUCell\n",
    "\n",
    "        self.encoder = RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        self.decoder_items = RNNCell(hidden_size, hidden_size)\n",
    "        \n",
    "        self.embedding = nn.Linear(self.input_size,hidden_size)\n",
    "\n",
    "        self.W1 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.W2 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.v1 = nn.Linear(weight_size, 1, bias=False)\n",
    "        \n",
    "        self.W3 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.W4 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.W5 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.v2 = nn.Linear(weight_size, 1, bias=False)\n",
    "        \n",
    "        self.W6 = nn.Linear(hidden_size,weight_size,bias=False)\n",
    "        self.W7 = nn.Linear(hidden_size*2,weight_size,bias=False)\n",
    "        self.v3 = nn.Linear(weight_size,1)\n",
    "        \n",
    "        self.W_ori = nn.Linear(hidden_size*3,6)\n",
    "        \n",
    "        \n",
    "        self.W8 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.W9 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.v4 = nn.Linear(weight_size, 1, bias=False)\n",
    "        \n",
    "        self.W10 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.W11 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.W12 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.v5 = nn.Linear(weight_size, 1, bias=False)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, items):\n",
    "        batch_size = items.shape[0]\n",
    "        decoder_seq_len = items.shape[1]\n",
    "        items = self.embedding(items)\n",
    "        encoder_output, hc = self.encoder(items)\n",
    "\n",
    "        # Decoding states initialization\n",
    "        hidden_items = encoder_output[:, -1, :] #hidden state for decoder is the last timestep's output of encoder \n",
    "        decoder_items_input = to_cuda(torch.rand(batch_size, self.hidden_size))   #%%%%%%%%%%%% decoder input research\n",
    "        \n",
    "        # Decoding with attention             \n",
    "        probs_seq = []\n",
    "        probs_ori = []\n",
    "        probs_boxes = []\n",
    "        encoder_output = encoder_output.transpose(1, 0) #Transpose the matrix for mm\n",
    "        decoder_output_items = torch.empty(batch_size,1,self.hidden_size)\n",
    "        for i in range(decoder_seq_len):\n",
    "            hidden_items = self.decoder_items(decoder_items_input, hidden_items) \n",
    "            \n",
    "            if decoder_output_items.shape[1] == 1:\n",
    "                decoder_output_items = hidden_items.unsqueeze(1)\n",
    "            else:\n",
    "                decoder_output_items = torch.cat((decoder_output_items,hidden_items.unsqueeze(1)),dim=1)\n",
    "                \n",
    "            # Computing Intra-attention\n",
    "            sm_intra = torch.tanh(self.W1(decoder_output_items.transpose(1, 0)) + self.W2(hidden_items))\n",
    "            out_intra = self.v1(sm_intra)\n",
    "            attnd = torch.log_softmax(out_intra.transpose(0, 1).contiguous(), -1)\n",
    "            hidden_intra = (attnd*decoder_output_items).sum(dim=1)\n",
    "            \n",
    "            # Computing attention\n",
    "            sm = torch.tanh(self.W3(encoder_output) + self.W4(hidden_items) + self.W5(hidden_intra))\n",
    "            out_sm = self.v2(sm).squeeze()\n",
    "#             out = torch.log_softmax(out_sm.transpose(0, 1).contiguous(), -1)\n",
    "            out = out_sm.transpose(0, 1).contiguous()\n",
    "            probs_seq.append(out.clone())\n",
    "            \n",
    "            # Orientation Probs\n",
    "            sm_ori = torch.tanh(self.W6(encoder_output) + self.W7(torch.cat((hidden_items.unsqueeze(1),hidden_intra.unsqueeze(1)),dim=2).transpose(1, 0)))\n",
    "            out_ori = self.v3(sm_ori)\n",
    "            attnc = torch.log_softmax(out_ori.transpose(0, 1).contiguous(), -1)\n",
    "            he = (attnc*encoder_output.transpose(0, 1)).sum(dim=1)\n",
    "            total_attention = torch.cat((he.unsqueeze(1),hidden_items.unsqueeze(1),hidden_intra.unsqueeze(1)),dim=2)\n",
    "#             out_ori = torch.log_softmax(self.W_ori(total_attention.squeeze()),-1)\n",
    "            out_ori = self.W_ori(total_attention.squeeze())\n",
    "            probs_ori.append(out_ori.clone())\n",
    "\n",
    "        probs_seq = torch.stack(probs_seq, dim=1)\n",
    "        probs_ori = torch.stack(probs_ori, dim=1)\n",
    "        return probs_seq,probs_ori\n",
    "    \n",
    "    \n",
    "def rot_func(rot):\n",
    "    rotation_indx = {0:(0,1,2,3),1:(0,2,1,3),2:(1,0,2,3),3:(1,2,0,3),4:(2,0,1,3),5:(2,1,0,3)}\n",
    "    return rotation_indx[rot]\n",
    "\n",
    "rot_func_v = np.vectorize(rot_func)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Env():\n",
    "    def __init__(self,BATCH_SIZE,ITEMS_SEQ_LN,INPUT_SIZE):\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.ITEMS_SEQ_LN = ITEMS_SEQ_LN\n",
    "        self.INPUT_SIZE = INPUT_SIZE\n",
    "        self.batch_indx = list(range(self.BATCH_SIZE))\n",
    "        self.expected_items_n = [self.ITEMS_SEQ_LN] * BATCH_SIZE\n",
    "        self.all_outs = {i:[] for i in range(self.BATCH_SIZE)}\n",
    "        self.base_indx_items = torch.arange(self.BATCH_SIZE).expand(self.INPUT_SIZE,self.ITEMS_SEQ_LN,self.BATCH_SIZE).T\n",
    "        self.base_indx_boxes = torch.arange(self.BATCH_SIZE).expand(self.ITEMS_SEQ_LN,self.BATCH_SIZE).T\n",
    "        self.items_batch_alligned = None\n",
    "        \n",
    "    def reset(self):\n",
    "        self.found = False\n",
    "        self.items_batch = []\n",
    "        self.boxes_batch = []\n",
    "        for j in range(self.BATCH_SIZE):\n",
    "            found = False\n",
    "            while not found:\n",
    "                boxes = torch.from_numpy(np.random.choice(range(300,1010,10),(3,))).expand(self.ITEMS_SEQ_LN,3).type(torch.FloatTensor)\n",
    "                box_wt_capacities = boxes.sum(1).unsqueeze(1)/50\n",
    "                boxes = torch.cat((boxes,box_wt_capacities),dim=1)\n",
    "                cubes = torch.randint(10,300,(self.ITEMS_SEQ_LN,self.INPUT_SIZE-1)) + torch.rand(self.ITEMS_SEQ_LN,self.INPUT_SIZE-1)\n",
    "                cubes_wts = torch.randint(1,4,(self.ITEMS_SEQ_LN,1)) + torch.rand(self.ITEMS_SEQ_LN,1)\n",
    "                cubes = torch.cat((cubes,cubes_wts),dim=1)\n",
    "                lookup_sum = boxes.sort(dim=1,descending=True)[0].expand(self.ITEMS_SEQ_LN,self.ITEMS_SEQ_LN,self.INPUT_SIZE) - cubes.sort(dim=1,descending=True)[0].unsqueeze(1)\n",
    "                found = (lookup_sum >= 0).all(2).any(1).all().item()\n",
    "                if found == True:\n",
    "                    self.items_batch.append(cubes)\n",
    "                    self.boxes_batch.append(boxes)\n",
    "        self.items_batch = torch.stack(self.items_batch,0)\n",
    "        self.boxes_batch = torch.stack(self.boxes_batch,0)\n",
    "        \n",
    "        self.batch_indx = list(range(self.BATCH_SIZE))\n",
    "        self.expected_items_n = [self.ITEMS_SEQ_LN] * BATCH_SIZE\n",
    "        self.all_outs = {i:[] for i in range(self.BATCH_SIZE)}\n",
    "        self.current_level = 0\n",
    "        self.items_batch_alligned = None\n",
    "        self.boxes_batch_alligned = None\n",
    "        \n",
    "        return self.items_batch,self.boxes_batch\n",
    "        \n",
    "        \n",
    "        self.base_indx_items = torch.arange(BATCH_SIZE).expand(self.INPUT_SIZE,self.ITEMS_SEQ_LN,self.BATCH_SIZE).T\n",
    "        self.base_indx_boxes = torch.arange(BATCH_SIZE).expand(self.ITEMS_SEQ_LN,self.BATCH_SIZE).T\n",
    "#         self.op = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def target_func(self,inputs):\n",
    "        result = simulate(inputs)\n",
    "        return pickle.dumps(result)\n",
    "    \n",
    "    def dict_update(self,data):\n",
    "        key,value = data[0],data[1:]\n",
    "        self.all_outs[key].append(value)\n",
    "        \n",
    "    def calc_reward(self,items_list,key,filled_items_indx,filled_items_HUs):\n",
    "        if len(self.all_outs[key]) > 0:\n",
    "            packed_items = items_list[filled_items_indx[key]]\n",
    "            if packed_items.size()[0] > 0:\n",
    "                total_vol = items_list[:,:3].prod(dim=1).sum().item()\n",
    "                packed_vol = packed_items[:,:3].prod(dim=1).sum().item()\n",
    "\n",
    "                total_surf = (2*items_list[:,(0,1)].prod(dim=1) + 2*items_list[:,(1,2)].prod(dim=1) + 2*items_list[:,(0,2)].prod(dim=1)).sum().item()\n",
    "                packed_surf = (2*packed_items[:,(0,1)].prod(dim=1) + 2*packed_items[:,(1,2)].prod(dim=1) + 2*packed_items[:,(0,2)].prod(dim=1)).sum().item()\n",
    "\n",
    "                portion_vol = packed_vol/total_vol\n",
    "                portion_surf = packed_surf/total_surf\n",
    "\n",
    "                used_boxes = torch.Tensor(filled_items_HUs[key])\n",
    "                total_boxes_vol = used_boxes[:,:3].prod(dim=1).sum().item()\n",
    "                total_boxes_surf = (2*used_boxes[:,(0,1)].prod(dim=1) + 2*used_boxes[:,(1,2)].prod(dim=1) + 2*used_boxes[:,(0,2)].prod(dim=1)).sum().item()\n",
    "                return (packed_vol/total_boxes_vol)#*portion_vol  + (packed_surf/total_boxes_surf)*portion_surf\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    def step(self,items_seq,items_ori,items_batch=None,boxes_batch=None):\n",
    "        if (items_batch != None) & (boxes_batch != None):\n",
    "            self.items_batch = items_batch\n",
    "            self.boxes_batch = boxes_batch\n",
    "            self.batch_indx = list(range(self.BATCH_SIZE))\n",
    "            self.expected_items_n = [self.ITEMS_SEQ_LN] * BATCH_SIZE\n",
    "            self.all_outs = {i:[] for i in range(self.BATCH_SIZE)}\n",
    "            self.current_level = 0\n",
    "            self.items_batch_alligned = None\n",
    "            self.boxes_batch_alligned = None\n",
    "        \n",
    "        items_seq_ = torch.LongTensor(items_seq).transpose(1,0).expand(self.INPUT_SIZE,self.ITEMS_SEQ_LN,self.BATCH_SIZE).transpose(2,0)\n",
    "        items_ori_ = items_ori[torch.arange(self.BATCH_SIZE).expand(self.ITEMS_SEQ_LN,self.BATCH_SIZE).transpose(1,0),torch.LongTensor(items_seq).expand(self.BATCH_SIZE,self.ITEMS_SEQ_LN)]\n",
    "        self.items_batch_alligned = self.items_batch[[self.base_indx_items,items_seq_,items_ori_]]\n",
    "        lookup_sm = self.boxes_batch.expand(self.ITEMS_SEQ_LN,self.BATCH_SIZE,self.ITEMS_SEQ_LN,self.INPUT_SIZE).transpose(1,0) - self.items_batch_alligned.unsqueeze(2)\n",
    "        validities = (lookup_sm >= 0).all(3).any(2).tolist()\n",
    "        new_seq = []\n",
    "        for i,j in zip(items_seq,validities):\n",
    "            new_seq.append([i[k] for k in range(len(i)) if j[k] == True])\n",
    "        self.batch_indx = [i for i in self.batch_indx if len(new_seq[i]) > 0]\n",
    "        items_seq = [i for i in new_seq if len(i) > 0]\n",
    "        \n",
    "        \n",
    "        zp = list(zip(self.batch_indx,self.items_batch[self.batch_indx],self.boxes_batch[self.batch_indx],items_seq,items_ori[self.batch_indx]))\n",
    "        p = Pool(10)\n",
    "        out = p.map(self.target_func,zp)\n",
    "        p.close()\n",
    "        p.join()\n",
    "        out = [pickle.loads(i) for i in out]\n",
    "\n",
    "        out_series = pd.Series(out)\n",
    "        _ = out_series.apply(lambda x: self.dict_update(x))\n",
    "#         out = [i for i in out if i[1] < i[2]]\n",
    "\n",
    "        self.batch_indx = [i[0] for i in out]\n",
    "\n",
    "        self.current_level += 1\n",
    "\n",
    "        items_seq = [i[5] for i in out]\n",
    "        all_rewards = [i[-1]*i[-2] for i in out]\n",
    "            \n",
    "#         filled_items_indx = {i:[i[2] for i in j] for i,j in self.all_outs.items() if len(j) > 0}\n",
    "#         filled_items_HUs = {i:[i[7] for i in j if len(i[7]) > 0] for i,j in self.all_outs.items()}\n",
    "#         all_rewards = [self.calc_reward(self.items_batch[i],i,filled_items_indx,filled_items_HUs) for i in range(self.BATCH_SIZE)]\n",
    "        return all_rewards\n",
    "    \n",
    "    \n",
    "    \n",
    "gamma = 0.99\n",
    "lamda = 0.95\n",
    "clip_ratio = 0.2\n",
    "lr_pi = 1e-4\n",
    "target_kl = 0.01\n",
    "train_pi_iter = 2\n",
    "accs = []\n",
    "EPOCH = 2000\n",
    "BATCH_SIZE = 128\n",
    "INPUT_SIZE = 4\n",
    "HIDDEN_SIZE = 256\n",
    "WEIGHT_SIZE = 10\n",
    "ITEMS_SEQ_LN = 10\n",
    "MODEL_INPUT_SIZE = 8\n",
    "alpha = 0.5\n",
    "\n",
    "\n",
    "ptr_net = PointerNetwork(MODEL_INPUT_SIZE,HIDDEN_SIZE,WEIGHT_SIZE,ITEMS_SEQ_LN)\n",
    "if torch.cuda.is_available():\n",
    "    ptr_net.cuda()\n",
    "optim_actor = torch.optim.Adam(ptr_net.parameters(), lr=lr_pi)\n",
    "\n",
    "env = Env(BATCH_SIZE, ITEMS_SEQ_LN, INPUT_SIZE)\n",
    "\n",
    "traj_n = 50000\n",
    "losses_n = []\n",
    "rews_n = []\n",
    "best_reward = 0\n",
    "for t in range(traj_n):\n",
    "    print('&&&&&&&&&&&&&&&',t,'&&&&&&&&&&&&&&&&')\n",
    "    \n",
    "#     if t % 500 == 0:\n",
    "#         lr_pi *= 0.96\n",
    "#         print('lr changed to',lr_pi)\n",
    "#         optim_actor = torch.optim.Adam(ptr_net.parameters(), lr=lr_pi)\n",
    "    \n",
    "    env = Env(BATCH_SIZE, ITEMS_SEQ_LN, INPUT_SIZE)\n",
    "    items_batch,boxes_batch = env.reset()\n",
    "    inp = torch.cat((items_batch,boxes_batch),2)\n",
    "    \n",
    "    probs_seq,probs_ori = ptr_net.forward(inp)\n",
    "    \n",
    "    m_ori = Categorical(logits=probs_ori)\n",
    "    m_seq = Categorical(logits=probs_seq)\n",
    "    \n",
    "#     ori = get_action(probs_ori)\n",
    "    ori = m_ori.sample()\n",
    "    ori_log_p = m_ori.log_prob(ori)\n",
    "    items_ori = rot_func_v(ori)\n",
    "    items_ori = [np.expand_dims(i,2) for i in items_ori]\n",
    "    items_ori = np.concatenate(items_ori,2)\n",
    "#     items_seq = get_action(probs_seq).tolist()\n",
    "    items_seq = m_seq.sample()\n",
    "    seq_log_p = m_seq.log_prob(items_seq)\n",
    "    rewards = env.step(items_seq,items_ori)\n",
    "    rewards = torch.Tensor(rewards)\n",
    "    print('reward',rewards.mean().item())\n",
    "    if rewards.mean().item() >= best_reward:\n",
    "        torch.save(ptr_net,'ptr_net_best.pt')\n",
    "        best_reward = rewards.mean().item()\n",
    "    if t % 10 == 0:\n",
    "        torch.save(ptr_net,'ptr_net_regular.pt')\n",
    "    policies = [probs_seq,probs_ori]\n",
    "    learn_indx = random.choice([0,1])\n",
    "#     print('learn_indx',learn_indx)\n",
    "#     old_policy = policies[learn_indx].detach()\n",
    "    rews = []\n",
    "    losses_coll = {0:[],1:[],2:[]}\n",
    "    losses_indx = random.choice([0,1,2])\n",
    "    env_outs = []\n",
    "    for k in range(train_pi_iter):\n",
    "        print('k',k)\n",
    "        probs_seq_,probs_ori_ = ptr_net.forward(inp)\n",
    "        m_ori_ = Categorical(logits=probs_ori_)\n",
    "        m_seq_ = Categorical(logits=probs_seq_)\n",
    "        \n",
    "        ori_log_p_ = m_ori_.log_prob(ori)\n",
    "        seq_log_p_ = m_seq_.log_prob(items_seq)\n",
    "        \n",
    "#         policies_ = [probs_seq_,probs_ori_]\n",
    "#         new_policy = policies_[learn_indx]\n",
    "        \n",
    "#         ratio = torch.exp(new_policy-old_policy).mean(2).mean(1)\n",
    "#         clip_adv = torch.clamp(ratio, 1-clip_ratio, 1+clip_ratio) * rewards\n",
    "#         loss_pi = -(torch.min(ratio * rewards, clip_adv)).mean()\n",
    "        ratio_seq = torch.exp(seq_log_p_ - seq_log_p.detach())\n",
    "        ratio_ori = torch.exp(ori_log_p_ - ori_log_p.detach())\n",
    "        \n",
    "        \n",
    "\n",
    "        clip_adv_seq = torch.clamp(ratio_seq, 1-clip_ratio, 1+clip_ratio) * rewards.unsqueeze(1)\n",
    "        loss_seq = -(torch.min(ratio_seq * rewards.unsqueeze(1), clip_adv_seq)).mean()\n",
    "        \n",
    "        clip_adv_ori = torch.clamp(ratio_ori, 1-clip_ratio, 1+clip_ratio) * rewards.unsqueeze(1)\n",
    "        loss_ori = -(torch.min(ratio_ori * rewards.unsqueeze(1), clip_adv_ori)).mean()\n",
    "        \n",
    "        print('loss',loss_seq.item(),loss_ori.item())\n",
    "#         losses.append((loss_seq.item(),loss_ori.item()))\n",
    "        optim_actor.zero_grad()\n",
    "        losses = [loss_seq,loss_ori,alpha*loss_seq+alpha*loss_ori]\n",
    "        \n",
    "        print('losses_indx',losses_indx)\n",
    "        loss_selected = losses[losses_indx]\n",
    "        losses_coll[losses_indx].append(loss_selected.item())\n",
    "        \n",
    "        loss_selected.backward()\n",
    "        optim_actor.step()\n",
    "\n",
    "        \n",
    "        \n",
    "        probs_seq_dummy,probs_ori_dummy = ptr_net.forward(inp)\n",
    "        ori_dummy = get_action(probs_ori_dummy)\n",
    "        items_ori_dummy = rot_func_v(ori_dummy)\n",
    "        items_seq_dummy = get_action(probs_seq_dummy).tolist()\n",
    "        items_ori_dummy = [np.expand_dims(i,2) for i in items_ori_dummy]\n",
    "        items_ori_dummy = np.concatenate(items_ori_dummy,2)\n",
    "\n",
    "        rewards_dummy = env.step(items_seq_dummy,items_ori_dummy,items_batch,boxes_batch)\n",
    "        rewards_dummy = torch.Tensor(rewards_dummy)\n",
    "        rews.append(rewards_dummy.mean().item())\n",
    "        print(rewards_dummy.mean())\n",
    "        \n",
    "    losses_n.append(losses_coll)\n",
    "    rews_n.append(rews)\n",
    "    env_outs.append(env.all_outs)\n",
    "    pickle.dump(losses_n,open('losses_n.pkl','wb'))\n",
    "    pickle.dump(rews_n,open('rews_n.pkl','wb'))\n",
    "    pickle.dump(env_outs,open('env_all_outs.pkl','wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
