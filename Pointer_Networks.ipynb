{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "# from model import PointerNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(x):\n",
    "    if torch.cuda.is_available():\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, weight_size, is_GRU=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_size = weight_size\n",
    "        self.is_GRU = is_GRU\n",
    "\n",
    "        if self.is_GRU:\n",
    "            RNN = nn.GRU\n",
    "            RNNCell = nn.GRUCell\n",
    "        else:\n",
    "            RNN = nn.LSTM\n",
    "            RNNCell = nn.LSTMCell\n",
    "\n",
    "        self.encoder = RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.decoder = RNNCell(input_size, hidden_size)\n",
    "        \n",
    "        self.W1 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.W2 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.v1 = nn.Linear(weight_size, 1, bias=False)\n",
    "        \n",
    "        self.W3 = nn.Linear(hidden_size, weight_size, bias=False) \n",
    "        self.W4 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.W5 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.v2 = nn.Linear(weight_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size = input.shape[0]\n",
    "        decoder_seq_len = input.shape[1]\n",
    "\n",
    "        encoder_output, hc = self.encoder(input)\n",
    "#         print('enc',encoder_output.shape)\n",
    "\n",
    "        # Decoding states initialization\n",
    "        hidden = encoder_output[:, -1, :] #hidden state for decoder is the last timestep's output of encoder \n",
    "        if not self.is_GRU: #For LSTM, cell state is the sencond state output\n",
    "            cell = hc[1][-1, :, :]\n",
    "        decoder_input = to_cuda(torch.rand(batch_size, self.input_size))  \n",
    "        \n",
    "        # Decoding with attention             \n",
    "        probs = []\n",
    "        encoder_output = encoder_output.transpose(1, 0) #Transpose the matrix for mm\n",
    "        \n",
    "        decoder_output = torch.empty(batch_size,1,self.hidden_size)\n",
    "        for i in range(decoder_seq_len):  \n",
    "            if self.is_GRU:\n",
    "                hidden = self.decoder(decoder_input, hidden) \n",
    "            else:\n",
    "                hidden, decoder_hc = self.decoder(decoder_input, (hidden, cell))\n",
    "            \n",
    "            if decoder_output.shape[1] == 1:\n",
    "                decoder_output = hidden.unsqueeze(1)\n",
    "            else:\n",
    "                decoder_output = torch.cat((decoder_output,hidden.unsqueeze(1)),dim=1)\n",
    "                \n",
    "            # Computing Intra-attention\n",
    "            sm = torch.tanh(self.W1(decoder_output.transpose(1, 0)) + self.W2(hidden))\n",
    "            out = self.v1(sm)\n",
    "            out = torch.log_softmax(out.transpose(0, 1).contiguous(), -1)\n",
    "            hidden_intra = (out*decoder_output).sum(dim=1)\n",
    "            \n",
    "            # Computing attention\n",
    "            sum = torch.tanh(self.W3(encoder_output) + self.W4(hidden) + self.W5(hidden_intra))\n",
    "            out = self.v2(sum).squeeze()        \n",
    "            out = torch.log_softmax(out.transpose(0, 1).contiguous(), -1)\n",
    "            probs.append(out)\n",
    "\n",
    "        probs = torch.stack(probs, dim=1)           \n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training... \n",
      "Epoch: 0, Loss: 1.43681\n",
      "Acc: 0.00%\n",
      "Epoch: 2, Loss: 0.96951\n",
      "Acc: 0.00%\n",
      "Epoch: 4, Loss: 0.74508\n",
      "Acc: 3.00%\n",
      "Epoch: 6, Loss: 0.64369\n",
      "Acc: 10.00%\n",
      "Epoch: 8, Loss: 0.49641\n",
      "Acc: 24.00%\n",
      "Epoch: 10, Loss: 0.48426\n",
      "Acc: 17.00%\n",
      "Epoch: 12, Loss: 0.56842\n",
      "Acc: 19.00%\n",
      "Epoch: 14, Loss: 0.40975\n",
      "Acc: 19.00%\n",
      "Epoch: 16, Loss: 0.47306\n",
      "Acc: 15.00%\n",
      "Epoch: 18, Loss: 0.31396\n",
      "Acc: 39.00%\n",
      "Epoch: 20, Loss: 0.29361\n",
      "Acc: 32.00%\n",
      "Epoch: 22, Loss: 1.64447\n",
      "Acc: 0.00%\n",
      "Epoch: 24, Loss: 0.40685\n",
      "Acc: 23.00%\n",
      "Epoch: 26, Loss: 0.33556\n",
      "Acc: 41.00%\n",
      "Epoch: 28, Loss: 0.31446\n",
      "Acc: 26.00%\n",
      "Epoch: 30, Loss: 0.29212\n",
      "Acc: 35.00%\n",
      "Epoch: 32, Loss: 0.31778\n",
      "Acc: 34.00%\n",
      "Epoch: 34, Loss: 0.25916\n",
      "Acc: 43.00%\n",
      "Epoch: 36, Loss: 0.25660\n",
      "Acc: 42.00%\n",
      "Epoch: 38, Loss: 0.31484\n",
      "Acc: 24.00%\n",
      "Epoch: 40, Loss: 0.28383\n",
      "Acc: 37.00%\n",
      "Epoch: 42, Loss: 0.21819\n",
      "Acc: 53.00%\n",
      "Epoch: 44, Loss: 0.21600\n",
      "Acc: 56.00%\n",
      "Epoch: 46, Loss: 0.20875\n",
      "Acc: 56.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-6c61eb373573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-eb8d6f1f32a5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_GRU\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#For LSTM, cell state is the sencond state output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mdecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_cuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m# Decoding with attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-eb8d6f1f32a5>\u001b[0m in \u001b[0;36mto_cuda\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_cuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 250\n",
    "DATA_SIZE = 10000\n",
    "INPUT_SIZE = 1\n",
    "HIDDEN_SIZE = 512\n",
    "WEIGHT_SIZE = 256\n",
    "LR = 0.001\n",
    "\n",
    "\n",
    "def getdata(experiment=1, data_size=None):\n",
    "    if experiment == 1:\n",
    "        high = 100\n",
    "        senlen = 5\n",
    "        x = np.array([np.random.choice(range(high), senlen, replace=False)\n",
    "                      for _ in range(data_size)])\n",
    "        y = np.argsort(x)\n",
    "    elif experiment == 2:\n",
    "        high = 1000\n",
    "        senlen = 10\n",
    "        x = np.array([np.random.choice(range(high), senlen, replace=False)\n",
    "                      for _ in range(data_size)])\n",
    "        y = np.argsort(x)\n",
    "    elif experiment == 3:\n",
    "        senlen = 5\n",
    "        x = np.array([np.random.random(senlen) for _ in range(data_size)])\n",
    "        y = np.argsort(x)\n",
    "    elif experiment == 4:\n",
    "        senlen = 10\n",
    "        x = np.array([np.random.random(senlen) for _ in range(data_size)])\n",
    "        y = np.argsort(x)\n",
    "    return x, y\n",
    "\n",
    "def evaluate(model, X, Y):\n",
    "    probs = model(X) \n",
    "    prob, indices = torch.max(probs, 2) \n",
    "    equal_cnt = sum([1 if torch.equal(index.detach(), y.detach()) else 0 for index, y in zip(indices, Y)])\n",
    "    accuracy = equal_cnt/len(X)\n",
    "    print('Acc: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "#Get Dataset\n",
    "x, y = getdata(experiment=2, data_size = DATA_SIZE)\n",
    "x = to_cuda(torch.FloatTensor(x).unsqueeze(2))     \n",
    "y = to_cuda(torch.LongTensor(y)) \n",
    "#Split Dataset\n",
    "train_size = (int)(DATA_SIZE * 0.9)\n",
    "train_X = x[:train_size]\n",
    "train_Y = y[:train_size]\n",
    "test_X = x[train_size:]\n",
    "test_Y = y[train_size:]\n",
    "#Build DataLoader\n",
    "train_data = Data.TensorDataset(train_X, train_Y)\n",
    "data_loader = Data.DataLoader(\n",
    "    dataset = train_data,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "\n",
    "#Define the Model\n",
    "model = PointerNetwork(INPUT_SIZE, HIDDEN_SIZE, WEIGHT_SIZE, is_GRU=False)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fun = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#Training...\n",
    "print('Training... ')\n",
    "for epoch in range(EPOCH):\n",
    "    for (batch_x, batch_y) in data_loader:\n",
    "        probs = model(batch_x)         \n",
    "        outputs = probs.view(-1, batch_x.shape[1])\n",
    "        batch_y = batch_y.view(-1) \n",
    "        loss = loss_fun(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        print('Epoch: {}, Loss: {:.5f}'.format(epoch, loss.item()))\n",
    "        indx = torch.randperm(train_X.shape[0])[:100]\n",
    "        evaluate(model, train_X[indx], train_Y[indx])\n",
    "#Test...    \n",
    "print('Test...')\n",
    "evaluate(model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 62.00%\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_X[500:700], test_Y[500:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([92, 26,  8, 22, 81, 51, 81, 49, 38, 28, 74, 77, 83, 55, 86,  7, 64, 54,\n",
       "        44, 13, 18, 48,  8,  7, 63, 14, 62, 72, 59, 71])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample =torch.randint(100,(30,))\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = to_cuda(sample.view(2,15,1).type(torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model(sample)\n",
    "prob, indices = torch.max(probs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[92.],\n",
       "         [26.],\n",
       "         [ 8.],\n",
       "         [22.],\n",
       "         [81.],\n",
       "         [51.],\n",
       "         [81.],\n",
       "         [49.],\n",
       "         [38.],\n",
       "         [28.],\n",
       "         [74.],\n",
       "         [77.],\n",
       "         [83.],\n",
       "         [55.],\n",
       "         [86.]],\n",
       "\n",
       "        [[ 7.],\n",
       "         [64.],\n",
       "         [54.],\n",
       "         [44.],\n",
       "         [13.],\n",
       "         [18.],\n",
       "         [48.],\n",
       "         [ 8.],\n",
       "         [ 7.],\n",
       "         [63.],\n",
       "         [14.],\n",
       "         [62.],\n",
       "         [72.],\n",
       "         [59.],\n",
       "         [71.]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3,  9,  8,  5, 10, 10,  6, 14,  0,  0,  2,  2,  2,  2],\n",
       "        [ 8,  0,  7,  5,  3,  6, 13, 11,  1, 12,  8,  8,  8,  8,  8]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.],\n",
       "        [ 7.],\n",
       "        [ 8.],\n",
       "        [18.],\n",
       "        [44.],\n",
       "        [48.],\n",
       "        [59.],\n",
       "        [62.],\n",
       "        [64.],\n",
       "        [72.],\n",
       "        [ 7.],\n",
       "        [ 7.],\n",
       "        [ 7.],\n",
       "        [ 7.],\n",
       "        [ 7.]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1][indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([7.], device='cuda:0'),\n",
       " tensor([7.], device='cuda:0'),\n",
       " tensor([8.], device='cuda:0'),\n",
       " tensor([13.], device='cuda:0'),\n",
       " tensor([14.], device='cuda:0'),\n",
       " tensor([18.], device='cuda:0'),\n",
       " tensor([44.], device='cuda:0'),\n",
       " tensor([48.], device='cuda:0'),\n",
       " tensor([54.], device='cuda:0'),\n",
       " tensor([59.], device='cuda:0'),\n",
       " tensor([62.], device='cuda:0'),\n",
       " tensor([63.], device='cuda:0'),\n",
       " tensor([64.], device='cuda:0'),\n",
       " tensor([71.], device='cuda:0'),\n",
       " tensor([72.], device='cuda:0')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
